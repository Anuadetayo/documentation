# make a new virtualenv so we don't use the main docs one, which is why we're
# not using $VIRTUAL_ENV here.
export VIRTUAL_ENV  := ".venv"

# TODO: make it /scripts on windows?
export BIN := VIRTUAL_ENV + "/bin"
export PIP := BIN + "/python -m pip"
# enforce our chosen pip compile flags
export COMPILE := BIN + "/pip-compile --allow-unsafe --generate-hashes"


# list available commands
default:
    @{{ just_executable() }} --list


# clean up temporary files
clean:
    rm -rf .venv


# ensure valid virtualenv
virtualenv:
    #!/usr/bin/env bash
    PYTHON_VERSION=$(which python3.9)

    # create venv and upgrade pip
    test -d $VIRTUAL_ENV || { $PYTHON_VERSION -m venv $VIRTUAL_ENV && $PIP install --upgrade pip; }

    # ensure we have pip-tools so we can run pip-compile
    test -e $BIN/pip-compile || $PIP install pip-tools


# update requirements.prod.txt if requirement.prod.in has changed
requirements-prod: virtualenv
    #!/usr/bin/env bash
    # exit if .in file is older than .txt file (-nt = 'newer than', but we negate with || to avoid error exit code)
    test requirements.prod.in -nt requirements.prod.txt || exit 0
    $COMPILE --output-file=requirements.prod.txt requirements.prod.in


# update requirements.dev.txt if requirements.dev.in has changed
requirements-dev: requirements-prod
    #!/usr/bin/env bash
    # exit if .in file is older than .txt file (-nt = 'newer than', but we negate with || to avoid error exit code)
    test requirements.dev.in -nt requirements.dev.txt || exit 0
    $COMPILE --output-file=requirements.dev.txt requirements.dev.in


# ensure prod requirements installed and up to date
prodenv: requirements-prod
    #!/usr/bin/env bash
    # exit if .txt file has not changed since we installed them (-nt == "newer than', but we negate with || to avoid error exit code)
    test requirements.prod.txt -nt $VIRTUAL_ENV/.prod || exit 0

    $PIP install -r requirements.prod.txt
    touch $VIRTUAL_ENV/.prod


# && dependencies are run after the recipe has run. Needs just>=0.9.9. This is
# a killer feature over Makefiles.
#
# ensure dev requirements installed and up to date
devenv: prodenv requirements-dev
    #!/usr/bin/env bash
    # exit if .txt file has not changed since we installed them (-nt == "newer than', but we negate with || to avoid error exit code)
    test requirements.dev.txt -nt $VIRTUAL_ENV/.dev || exit 0

    $PIP install -r requirements.dev.txt
    touch $VIRTUAL_ENV/.dev


# upgrade dev or prod dependencies (all by default, specify package to upgrade single package)
upgrade env package="": virtualenv
    #!/usr/bin/env bash
    opts="--upgrade"
    test -z "{{ package }}" || opts="--upgrade-package {{ package }}"
    $COMPILE $opts --output-file=requirements.{{ env }}.txt requirements.{{ env }}.in


# upgrade the pinned version of databuilder
upgrade-databuilder: devenv
    $BIN/python update-version.py


# Run the tests
test: devenv
    #!/usr/bin/env bash
    set -euo pipefail
    # Use xargs here over find with the -exec option.
    # xargs produces a non-exit error code when command it runs fails.
    find snippets/ -type f -name "*.py" -print0 | xargs -0 -n 1 "$BIN"/python


# runs the format (black), sort (isort) and lint (flake8) check but does not change any files
check: devenv
    #!/usr/bin/env bash
    # config lives in the project root, so run commands there
    cd {{parent_directory(justfile_directory())}}
    databuilder/$BIN/black --check databuilder/
    databuilder/$BIN/isort --check-only --diff databuilder/
    databuilder/$BIN/flake8 databuilder/


# fix formatting and import sort ordering
fix: devenv
    #!/usr/bin/env bash
    # config lives in the project root, so run commands there
    cd {{parent_directory(justfile_directory())}}
    databuilder/$BIN/black databuilder/
    databuilder/$BIN/isort databuilder/


# Run the dataset definitions.
check-dataset-definitions: devenv
    #!/usr/bin/env bash
    set -euo pipefail

    cd {{parent_directory(justfile_directory())}}

    for f in ./databuilder/ehrql-tutorial-examples/*dataset_definition.py; do
      # By convention, we name dataset definition as: IDENTIFIER_DATASOURCENAME_dataset_definition.py
      DATASOURCENAME=`echo "$f" | cut -d'_' -f2`
      databuilder/$BIN/databuilder generate-dataset "$f" --dummy-tables "./databuilder/ehrql-tutorial-examples/example-data/$DATASOURCENAME/"
    done


# Check the dataset definition outputs are current
check-dataset-definitions-outputs-are-current: devenv
    #!/usr/bin/env bash
    set -euo pipefail

    cd {{parent_directory(justfile_directory())}}

    # https://stackoverflow.com/questions/3878624/how-do-i-programmatically-determine-if-there-are-uncommitted-changes
    # git diff --exit-code won't pick up untracked files, which we also want to check for.
    if [[ -z $(git status --porcelain ./databuilder/ehrql-tutorial-examples/outputs/; git clean -nd ./databuilder/ehrql-tutorial-examples/outputs/) ]]
    then
      echo "Dataset definition outputs directory is current and free of other files/directories."
    else
      echo "Dataset definition outputs contains files/directories not in the repository."
      exit 1
    fi


build-dataset-definitions-outputs: devenv
    #!/usr/bin/env bash
    set -euo pipefail

    cd {{parent_directory(justfile_directory())}}

    for f in ./databuilder/ehrql-tutorial-examples/*dataset_definition.py; do
      # By convention, we name dataset definition as: IDENTIFIER_DATASOURCENAME_dataset_definition.py
      DATASOURCENAME=`echo "$f" | cut -d'_' -f2`
      FILENAME="$(basename "$f" .py).csv"
      databuilder/$BIN/databuilder generate-dataset "$f" --dummy-tables "./databuilder/ehrql-tutorial-examples/example-data/$DATASOURCENAME/" --output "./databuilder/ehrql-tutorial-examples/outputs/$FILENAME"
    done

# Requires OpenSAFELY CLI and Docker installed.
# Runs all actions in the `project.yaml`
build-dataset-definitions-outputs-docker-project:
    #!/usr/bin/env bash
    set -euo pipefail
    # Instead of entering the directory, We could use opensafely --project-dir
    # But we would end up with a metadata directory in this directory then.
    cd "ehrql-tutorial-examples"
    opensafely run run_all --force-run-dependencies

# Run the dev project
run: devenv
    echo "Not implemented yet"
